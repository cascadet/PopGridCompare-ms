{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area Var\n",
    "\n",
    "Notebook to explore population distrubtions across sub-national units by gridded population dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats, gen_zonal_stats\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions\n",
    "def zone_loop(polys_in, rst_list, stats_type, col, split, add = None):\n",
    "    \"\"\" Function loops through rasters, calcs zonal_stats and returns stats as a data frame.\n",
    "    Args:\n",
    "        polys_in = polygons\n",
    "        rst_list = list of paths & fns of rasters\n",
    "        stats_type = stats type for each poly gone (see zonal stats)\n",
    "        col = column to merge it all\n",
    "        split = where to split the file name string (e.g. _matched.tif)\n",
    "        add = additional custom stats function must be a dict {'mymean':mymean} (see rasterstats documentation)\n",
    "    \"\"\"\n",
    "    \n",
    "    # copy polys to write out\n",
    "    polys_out = polys_in.copy()\n",
    "    \n",
    "    for rst in rst_list:\n",
    "        \n",
    "        # Get data name\n",
    "        data = rst.split(DATA_PATH+'interim/')[1].split(split)[0]\n",
    "        print('Started', data)\n",
    "        \n",
    "        # Run zonal stats\n",
    "        zs_feats = zonal_stats(polys_in, rst, stats=stats_type, add_stats = add, geojson_out=True)\n",
    "        zgdf = gpd.GeoDataFrame.from_features(zs_feats, crs=polys_in.crs)\n",
    "        \n",
    "        # Rename columns and merge\n",
    "        if add == None:\n",
    "            zgdf = zgdf.rename(columns={stats_type: data+'_'+stats_type})\n",
    "            polys_out = polys_out.merge(zgdf[[col, data+'_'+stats_type]], on = col, how = 'inner')\n",
    "        \n",
    "        else:\n",
    "            key = list(add.keys())[0]\n",
    "            zgdf = zgdf.rename(columns={stats_type: data+'_'+stats_type})\n",
    "            zgdf = zgdf.rename(columns={key: data+'_'+key})\n",
    "            polys_out = polys_out.merge(zgdf[[col, data+'_'+stats_type, data+'_'+key]], on = col, how = 'inner')\n",
    "    \n",
    "    return polys_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_prep(polys_fn, col):\n",
    "    \"function opens earth quake polygons for zonal loop\"\n",
    "    \n",
    "    # open\n",
    "    polys = gpd.read_file(polys_fn)\n",
    "    \n",
    "    # subset, be sure to check the admin level\n",
    "    polys = polys[['geometry', col]]\n",
    "    \n",
    "    return polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(polys_fn, rst_fns, GID_col, stats_type, split_str, add_dic):\n",
    "    \n",
    "    \"\"\" Finds area of polygons and then runs zonal statistics on them across gridded population rasters\n",
    "    Args:\n",
    "        polys_fn = path and file name of polygons (gdam usually)\n",
    "        rst_fns = glob list of raster names for zonal stats\n",
    "        GID_col = column of gdam level \n",
    "        stats_type = see zone_loop\n",
    "        split_str = see zone_loop\n",
    "        add_dic = see zone_loop\n",
    "    \"\"\"\n",
    "    \n",
    "    # open polys\n",
    "    polys = gpd.read_file(polys_fn)\n",
    "    \n",
    "    # calculate area\n",
    "    polys['area'] =  polys.to_crs('EPSG:3857').area\n",
    "    \n",
    "    # zonal stats\n",
    "    polys_zone = polys[['geometry', GID_col]]\n",
    "    polys_final = zone_loop(polys_in = polys_zone, rst_list = rst_fns, stats_type = stats_type, col = GID_col, \n",
    "                         split = split_str, add = add_dic)\n",
    "    \n",
    "    # merge\n",
    "    df_out = polys_final.merge(polys[[GID_col, 'area']], on = GID_col, how = 'inner')\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(data, x_col, y_col, custom_xlim, custom_ylim, label = None):\n",
    "    \n",
    "    \"\"\"Makes a 1 by five plot -- need to update titles and what not\n",
    "    Args:\n",
    "        data = df_out from make_data\n",
    "        x_col = x_column you want to plot\n",
    "        y_col = y_column you want to plat by gridded product\n",
    "        xlim = (min, max)\n",
    "        ylim = (min, max)\n",
    "        label = urban/rural\n",
    "    \"\"\"\n",
    "    \n",
    "    # set colors\n",
    "    ESRI16_c = 'blue'\n",
    "    GHS15_c = 'indigo'\n",
    "    GWPv4_c = 'deeppink'\n",
    "    LS15_c = 'deepskyblue'\n",
    "    WP16_c = 'forestgreen'\n",
    "    \n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(5, 1, figsize = (5, 16), sharex=True)\n",
    "    ws = 0.25\n",
    "    fig.subplots_adjust(wspace=ws)\n",
    "\n",
    "    axs[0].scatter(np.log10(data[x_col]), data['ESRI16_'+y_col], color = ESRI16_c, alpha = 0.5, s = 30, marker = '.')\n",
    "    axs[1].scatter(np.log10(data[x_col]), data['GHS15_'+y_col], color = GHS15_c, alpha = 0.5,s = 30, marker = '.')\n",
    "    axs[2].scatter(np.log10(data[x_col]), data['GPWv4_'+y_col], color = GWPv4_c,  alpha = 0.5, s = 30, marker = '.')\n",
    "    axs[3].scatter(np.log10(data[x_col]), data['LS15_'+y_col], color = LS15_c, alpha = 0.5, s = 30, marker = '.')\n",
    "    axs[4].scatter(np.log10(data[x_col]), data['WP16_'+y_col], color = WP16_c, alpha = 0.5, s = 30, marker = '.')\n",
    "\n",
    "    # Titles\n",
    "    axs[0].set_title('WPE-16', size = 12)\n",
    "    axs[1].set_title('GHS-15', size = 12)\n",
    "    axs[2].set_title('GWPv4-15', size = 12)\n",
    "    axs[3].set_title('LS-15', size = 12)\n",
    "    axs[4].set_title('WP-16', size = 12)\n",
    "    axs[4].set_xlabel('Admin Level 4 Area [log10]', fontsize = 15)\n",
    "    axs[2].set_ylabel('Std of pixel-level population '+label, fontsize = 15)\n",
    "\n",
    "    # lims\n",
    "    #plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start with Nepal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "DATA_PATH = '/Users/cascade/Github/PopGridCompare/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom stats for zonal stats\n",
    "def std(X):\n",
    "    return np.std(X)\n",
    "\n",
    "#args\n",
    "add_dic = {'std':std}\n",
    "geog = ''\n",
    "split_str = '_all_Nepal.tif'\n",
    "npl4_fn = DATA_PATH+'raw/GDAM/gadm36_NPL_shp/gadm36_NPL_3.shp'\n",
    "rst_fns = sorted(glob('/Users/cascade/Github/PopGridCompare/data/interim/*'+split_str))\n",
    "col = 'GID_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run it\n",
    "NPL = make_data(polys_fn = npl4_fn, rst_fns = rst_fns, GID_col = col, \n",
    "                stats_type = 'sum', split_str = split_str, add_dic = add_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def make_plot(data, x_col, custom_xlim, custom_ylim, label = None):\n",
    "make_plot(data = NPL, x_col = 'area', y_col = 'std', custom_xlim = (6,9), custom_ylim = (- 100,20000), label = 'RURAL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
