{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area Var\n",
    "\n",
    "Notebook to explore population distrubtions across sub-national units by gridded population dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "from rasterstats import zonal_stats, gen_zonal_stats\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Functions\n",
    "def zone_loop(polys_in, rst_list, stats_type, col, split, add = None):\n",
    "    \"\"\" Function loops through rasters, calcs zonal_stats and returns stats as a data frame.\n",
    "    Args:\n",
    "        polys_in = polygons\n",
    "        rst_list = list of paths & fns of rasters\n",
    "        stats_type = stats type for each poly gone (see zonal stats)\n",
    "        col = column to merge it all\n",
    "        split = where to split the file name string (e.g. _matched.tif)\n",
    "        add = additional custom stats function must be a dict {'mymean':mymean} (see rasterstats documentation)\n",
    "    \"\"\"\n",
    "    \n",
    "    # copy polys to write out\n",
    "    polys_out = polys_in.copy()\n",
    "    \n",
    "    for rst in rst_list:\n",
    "        \n",
    "        # Get data name\n",
    "        data = rst.split(DATA_PATH+'interim/')[1].split(split)[0]\n",
    "        print('Started', data)\n",
    "        \n",
    "        # Run zonal stats\n",
    "        zs_feats = zonal_stats(polys_in, rst, stats=stats_type, add_stats = add, geojson_out=True)\n",
    "        zgdf = gpd.GeoDataFrame.from_features(zs_feats, crs=polys_in.crs)\n",
    "        \n",
    "        # Rename columns and merge\n",
    "        if add == None:\n",
    "            zgdf = zgdf.rename(columns={stats_type: data+'_'+stats_type})\n",
    "            polys_out = polys_out.merge(zgdf[[col, data+'_'+stats_type]], on = col, how = 'inner')\n",
    "        \n",
    "        else:\n",
    "            key = list(add.keys())[0]\n",
    "            zgdf = zgdf.rename(columns={stats_type: data+'_'+stats_type})\n",
    "            zgdf = zgdf.rename(columns={key: data+'_'+key})\n",
    "            polys_out = polys_out.merge(zgdf[[col, data+'_'+stats_type, data+'_'+key]], on = col, how = 'inner')\n",
    "    \n",
    "    return polys_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_prep(polys_fn, col):\n",
    "    \"function opens earth quake polygons for zonal loop\"\n",
    "    \n",
    "    # open\n",
    "    polys = gpd.read_file(polys_fn)\n",
    "    \n",
    "    # subset, be sure to check the admin level\n",
    "    polys = polys[['geometry', col]]\n",
    "    \n",
    "    return polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(polys_fn, rst_fns, GID_col, stats_type, split_str, add_dic):\n",
    "    \n",
    "    \"\"\" Finds area of polygons and then runs zonal statistics on them across gridded population rasters\n",
    "    Args:\n",
    "        polys_fn = path and file name of polygons (was gdam, now GPWv4 grid polys)\n",
    "        rst_fns = glob list of raster names for zonal stats\n",
    "        GID_col = column of gdam level \n",
    "        stats_type = see zone_loop\n",
    "        split_str = see zone_loop\n",
    "        add_dic = see zone_loop\n",
    "    \"\"\"\n",
    "    \n",
    "    # open polys\n",
    "    polys = gpd.read_file(polys_fn)\n",
    "    \n",
    "#     # calculate area\n",
    "#     polys['area'] =  polys.to_crs('EPSG:3857').area\n",
    "    \n",
    "    # zonal stats\n",
    "    polys_zone = polys[['geometry', GID_col]]\n",
    "    polys_final = zone_loop(polys_in = polys_zone, rst_list = rst_fns, stats_type = stats_type, col = GID_col, \n",
    "                         split = split_str, add = add_dic)\n",
    "    \n",
    "    # merge\n",
    "    df_out = polys_final.merge(polys[[GID_col, 'AREAKM']], on = GID_col, how = 'inner')\n",
    "    \n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(data, x_col, y_col, custom_xlim, custom_ylim, fn_out = None):\n",
    "    \n",
    "    \"\"\"Makes a 1 by five plot -- need to update titles and what not\n",
    "    Args:\n",
    "        data = df_out from make_data\n",
    "        x_col = x_column you want to plot\n",
    "        y_col = y_column you want to plat by gridded product\n",
    "        custom_xlim = (min, max)\n",
    "        custom_ylim = (min, max)\n",
    "        fn_out = if not None, path and fn to save it out\n",
    "    \"\"\"\n",
    "    \n",
    "    # for log np.log10(data['ESRI16_'+y_col].astype('float32'))\n",
    "    \n",
    "    # set colors\n",
    "    ESRI16_c = 'blue'\n",
    "    GHS15_c = 'indigo'\n",
    "    GWPv4_c = 'deeppink'\n",
    "    LS15_c = 'deepskyblue'\n",
    "    WP16_c = 'forestgreen'\n",
    "    \n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(5, 1, figsize = (5, 18), sharex=True)\n",
    "    ws = 0.25\n",
    "    fig.subplots_adjust(wspace=ws)\n",
    "\n",
    "    axs[0].scatter(np.log10(data[x_col]), data['ESRI16_'+y_col].astype('float32'), color = ESRI16_c, alpha = 0.3, s = 30, marker = '.')\n",
    "    axs[1].scatter(np.log10(data[x_col]), data['GHS15_'+y_col].astype('float32'), color = GHS15_c, alpha = 0.3,s = 30, marker = '.')\n",
    "    axs[2].scatter(np.log10(data[x_col]), data['GPWv4_'+y_col].astype('float32'), color = GWPv4_c,  alpha = 0.3, s = 30, marker = '.')\n",
    "    axs[3].scatter(np.log10(data[x_col]), data['LS15_'+y_col].astype('float32'), color = LS15_c, alpha = 0.3, s = 30, marker = '.')\n",
    "    axs[4].scatter(np.log10(data[x_col]), data['WP16_'+y_col].astype('float32'), color = WP16_c, alpha = 0.3, s = 30, marker = '.')\n",
    "\n",
    "    # Titles\n",
    "    axs[0].legend(['WPE-16'], fontsize = 13, markerscale = 2)\n",
    "    axs[1].legend(['GHS-15'], fontsize = 13, markerscale = 2)\n",
    "    axs[2].legend(['GWPv4-15'], fontsize = 13, markerscale = 2)\n",
    "    axs[3].legend(['LS-15'], fontsize = 13, markerscale = 2)\n",
    "    axs[4].legend(['WP-16'], fontsize = 13, markerscale = 2)\n",
    "    axs[4].set_xlabel('Area Km$^2$ [log10]', fontsize = 20)\n",
    "    axs[2].set_ylabel('Std', fontsize = 20)\n",
    "\n",
    "    # lims\n",
    "    plt.setp(axs, xlim=custom_xlim, ylim=custom_ylim);\n",
    "    \n",
    "    # ticks\n",
    "    plt.rcParams['xtick.labelsize']=12\n",
    "    plt.rcParams['ytick.labelsize']=12\n",
    "    \n",
    "    # save\n",
    "    if fn_out != None:\n",
    "        plt.savefig(fn_out, dpi = 300, facecolor = 'white', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom stats for zonal stats\n",
    "def std(X):\n",
    "    return np.std(X)\n",
    "\n",
    "# Path\n",
    "DATA_PATH = '/Users/cascade/Github/PopGridCompare/data/'\n",
    "\n",
    "#args\n",
    "add_dic = {'std':std}\n",
    "geog = ''\n",
    "split_str = '_all_MMZ.tif' #NPL MMZ ECU change out\n",
    "fn_out = DATA_PATH+'FIGS/MS/Fig3_MMZ.png' #NPL MMZ ECU change out\n",
    "poly_fn = DATA_PATH+'interim/M3-M3-Z2.shp'#ECU-clip3.shp' #'raw/GPWv4-boundaries/gwpv4_npl_admin4.shp'' change out\n",
    "rst_fns = sorted(glob(DATA_PATH+'interim/*'+split_str))\n",
    "col = 'UBID' # col id from GPWv4 boundaries\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started ESRI16\n",
      "Started GHS15\n",
      "Started GPWv4\n",
      "Started LS15\n"
     ]
    }
   ],
   "source": [
    "# run it\n",
    "data = make_data(polys_fn = poly_fn, rst_fns = rst_fns, GID_col = col, \n",
    "                stats_type = 'sum', split_str = split_str, add_dic = add_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def make_plot(data, x_col, custom_xlim, custom_ylim, label = None):\n",
    "make_plot(data = data, x_col = 'AREAKM', \n",
    "          y_col = 'std', custom_xlim = (-.1,5), custom_ylim = (- 1, 10000),fn_out = fn_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
